#!/usr/bin/env python3
"""
Yahoo Auction Scraper Simple
==========================
Beautiful Soupä¾å­˜ãªã—ã®ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆ
"""

import requests
import re
import json
from datetime import datetime

class YahooAuctionScraperSimple:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def search_auctions(self, keyword="ãƒã‚¹ã‚¿ãƒ¼", max_items=10):
        """ã‚ªãƒ¼ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        
        # å®Ÿéš›ã®APIã¯ä½¿ã‚ãšã€ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿
        print(f"ğŸ” '{keyword}' æ¤œç´¢ä¸­...")
        
        sample_data = [
            {
                'title': f'ã‚¢ãƒ‹ãƒ¡ãƒã‚¹ã‚¿ãƒ¼ {keyword}',
                'price': 2500,
                'url': 'https://page.auctions.yahoo.co.jp/jp/auction/sample1',
                'seller': 'user123',
                'end_time': '2025-06-03 20:00',
                'watchers': 15,
                'bids': 3
            },
            {
                'title': f'ç¾å°‘å¥³ã‚¤ãƒ©ã‚¹ãƒˆ {keyword}',
                'price': 3200,
                'url': 'https://page.auctions.yahoo.co.jp/jp/auction/sample2',
                'seller': 'artist456',
                'end_time': '2025-06-03 21:30',
                'watchers': 28,
                'bids': 7
            },
            {
                'title': f'é™å®šç‰ˆ {keyword} B2ã‚µã‚¤ã‚º',
                'price': 4800,
                'url': 'https://page.auctions.yahoo.co.jp/jp/auction/sample3',
                'seller': 'collector789',
                'end_time': '2025-06-04 19:15',
                'watchers': 45,
                'bids': 12
            }
        ]
        
        print(f"âœ… {len(sample_data)}ä»¶å–å¾—")
        return sample_data[:max_items]
    
    def extract_with_regex(self, html_content):
        """æ­£è¦è¡¨ç¾ã§ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºï¼ˆBS4ä»£æ›¿ï¼‰"""
        
        items = []
        
        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
        titles = re.findall(r'<title[^>]*>([^<]+)</title>', html_content)
        
        # ä¾¡æ ¼æŠ½å‡º
        prices = re.findall(r'(\d+)å††', html_content)
        
        # URLæŠ½å‡º
        urls = re.findall(r'https?://[^\s<>"]+', html_content)
        
        return {
            'titles': titles,
            'prices': prices,
            'urls': urls
        }
    
    def analyze_market_trends(self, items):
        """å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        
        if not items:
            return "åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—"
        
        prices = [item['price'] for item in items]
        watchers = [item['watchers'] for item in items]
        
        analysis = {
            'total_items': len(items),
            'avg_price': sum(prices) / len(prices),
            'max_price': max(prices),
            'min_price': min(prices),
            'avg_watchers': sum(watchers) / len(watchers),
            'high_interest': [item for item in items if item['watchers'] > 20]
        }
        
        return analysis
    
    def generate_recommendation(self, analysis):
        """æ¨å¥¨ç­–å®š"""
        
        if not analysis or analysis == "åˆ†æãƒ‡ãƒ¼ã‚¿ãªã—":
            return ["ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚æ¨å¥¨ç­–ãªã—"]
        
        recommendations = [
            f"æ¨å¥¨ä¾¡æ ¼: {analysis['avg_price']:.0f}å††å‰å¾Œ",
            f"æ³¨ç›®åº¦ç›®æ¨™: {analysis['avg_watchers']:.0f}ã‚¦ã‚©ãƒƒãƒä»¥ä¸Š",
            f"ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸: {analysis['min_price']:.0f}å†† ã€œ {analysis['max_price']:.0f}å††",
            f"äººæ°—å•†å“æ•°: {len(analysis['high_interest'])}ä»¶"
        ]
        
        return recommendations

def main():
    """ã‚·ãƒ³ãƒ—ãƒ«ã‚¹ã‚¯ãƒ¬ãƒ¼ãƒ‘ãƒ¼å®Ÿè¡Œ"""
    
    scraper = YahooAuctionScraperSimple()
    
    print("ğŸ” Yahoo Auction Scraper Simple")
    print("=" * 40)
    
    # æ¤œç´¢å®Ÿè¡Œ
    items = scraper.search_auctions("ãƒã‚¹ã‚¿ãƒ¼ ã‚¢ãƒ‹ãƒ¡", 5)
    
    # çµæœè¡¨ç¤º
    print(f"\nğŸ“Š æ¤œç´¢çµæœ:")
    for i, item in enumerate(items, 1):
        print(f"{i}. {item['title']}")
        print(f"   ä¾¡æ ¼: {item['price']:,}å†† | ã‚¦ã‚©ãƒƒãƒ: {item['watchers']} | å…¥æœ­: {item['bids']}")
    
    # åˆ†æå®Ÿè¡Œ
    analysis = scraper.analyze_market_trends(items)
    
    # æ¨å¥¨ç”Ÿæˆ
    recommendations = scraper.generate_recommendation(analysis)
    
    print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
    for rec in recommendations:
        print(f"  â€¢ {rec}")
    
    # çµæœä¿å­˜
    result = {
        'timestamp': datetime.now().isoformat(),
        'search_keyword': 'ãƒã‚¹ã‚¿ãƒ¼ ã‚¢ãƒ‹ãƒ¡',
        'items': items,
        'analysis': analysis,
        'recommendations': recommendations
    }
    
    with open('yahoo_scraper_simple_result.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ çµæœä¿å­˜: yahoo_scraper_simple_result.json")

if __name__ == "__main__":
    main()