#!/usr/bin/env python3
"""
FANZAåŒäºº MCP Server - Note API ã‚¹ã‚¿ã‚¤ãƒ«
FANZAåŒäººãƒãƒ¼ã‚±ãƒƒãƒˆå°‚ç”¨ã®å£²ã‚Œç­‹åˆ†æãƒ»ç«¶åˆèª¿æŸ»ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ä¸è¦ï¼‰
"""

import asyncio
import json
import logging
import sys
from typing import Any, Dict, List, Optional, Sequence
from datetime import datetime, timedelta
import sqlite3
import os
from pathlib import Path

# MCP imports
try:
    from mcp.server import Server
    from mcp.types import (
        Resource, Tool, TextContent, ImageContent, EmbeddedResource,
        LoggingLevel
    )
except ImportError:
    print("MCP library not found. Install with: pip install mcp")
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("fanza-mcp")

class FanzaDoujinDataManager:
    """FANZAåŒäººå¸‚å ´ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db_path: str = "./fanza_market_data.db"):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS market_trends (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                category TEXT NOT NULL,
                trend_type TEXT NOT NULL,
                data TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # å•†å“ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                category TEXT,
                price_range TEXT,
                tags TEXT,
                success_factors TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS analysis_results (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                analysis_type TEXT NOT NULL,
                keywords TEXT,
                results TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        
        # åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        self.populate_initial_data()
    
    def populate_initial_data(self):
        """åˆæœŸå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
        cursor.execute("SELECT COUNT(*) FROM market_trends")
        if cursor.fetchone()[0] > 0:
            conn.close()
            return
        
        # FANZAåŒäººå¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ï¼ˆ2024-2025å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
        trend_data = [
            ("doujin_manga", "top_genres", json.dumps({
                "school_romance": {"popularity": 98, "price_range": "660-1320", "avg_sales": 2400, "competition": "æ¿€æˆ¦"},
                "office_lady": {"popularity": 92, "price_range": "550-1100", "avg_sales": 1800, "competition": "ä¸­ç¨‹åº¦"},
                "maid_cafe": {"popularity": 89, "price_range": "770-1540", "avg_sales": 2100, "competition": "ä¸­ç¨‹åº¦"},
                "nurse_hospital": {"popularity": 85, "price_range": "660-1320", "avg_sales": 1900, "competition": "ä¸­ç¨‹åº¦"},
                "teacher_student": {"popularity": 94, "price_range": "770-1430", "avg_sales": 2600, "competition": "æ¿€æˆ¦"}
            })),
            ("doujin_cg", "winning_themes", json.dumps({
                "uniform_jk": {"demand": 99, "avg_price": 1100, "success_rate": 0.89, "best_tags": "åˆ¶æœ,JK,æ”¾èª²å¾Œ"},
                "swimsuit_summer": {"demand": 94, "avg_price": 990, "success_rate": 0.82, "best_tags": "æ°´ç€,å¤,æµ·,ãƒ—ãƒ¼ãƒ«"},
                "maid_service": {"demand": 88, "avg_price": 1320, "success_rate": 0.85, "best_tags": "ãƒ¡ã‚¤ãƒ‰,ã”å¥‰ä»•,ãŠå¬¢æ§˜"},
                "office_suit": {"demand": 86, "avg_price": 1210, "success_rate": 0.78, "best_tags": "OL,ã‚¹ãƒ¼ãƒ„,æ®‹æ¥­"},
                "fantasy_elf": {"demand": 91, "avg_price": 1430, "success_rate": 0.87, "best_tags": "ã‚¨ãƒ«ãƒ•,ç•°ä¸–ç•Œ,é­”æ³•"}
            })),
            ("doujin_voice", "premium_categories", json.dumps({
                "binaural_asmr": {"price_premium": 2.8, "avg_price": 2200, "length_req": "60min+"},
                "character_drama": {"popularity": 96, "avg_price": 1650, "voice_actor_impact": 1.6},
                "situation_voice": {"demand": 93, "avg_price": 1430, "scenario_importance": 0.9},
                "healing_sleep": {"niche_demand": 88, "avg_price": 1980, "repeat_purchase": 0.75}
            }))
        ]
        
        for category, trend_type, data in trend_data:
            cursor.execute(
                "INSERT INTO market_trends (category, trend_type, data) VALUES (?, ?, ?)",
                (category, trend_type, data)
            )
        
        # FANZAåŒäººå®Ÿç¸¾ä¸Šä½å•†å“äº‹ä¾‹ï¼ˆåŒ¿ååŒ–æ¸ˆã¿ï¼‰
        success_products = [
            ("åˆ¶æœJKæ‹æ„›CGé›†", "doujin_cg", "standard", "#åˆ¶æœ,#JK,#æ‹æ„›,#å­¦åœ’,#ç´”æ„›", "é«˜ç”»è³ª,è¡¨æƒ…å·®åˆ†40æš,åˆ¶æœãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è±Šå¯Œ"),
            ("OLæ®‹æ¥­ãƒãƒ³ã‚¬", "doujin_manga", "premium", "#OL,#æ®‹æ¥­,#ã‚ªãƒ•ã‚£ã‚¹,#å¤§äºº,#ç§˜å¯†", "ãƒªã‚¢ãƒ«ãªè¨­å®š,æ„Ÿæƒ…ç§»å…¥ã—ã‚„ã™ã„,20ãƒšãƒ¼ã‚¸å®Œçµ"),
            ("ãƒ¡ã‚¤ãƒ‰ASMRéŸ³å£°", "doujin_voice", "premium", "#ãƒ¡ã‚¤ãƒ‰,#ASMR,#ç™’ã—,#ãƒã‚¤ãƒãƒ¼ãƒ©ãƒ«,#ãŠä¸–è©±", "äººæ°—å£°å„ª,90åˆ†åéŒ²,ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³è±Šå¯Œ"),
            ("ã‚¨ãƒ«ãƒ•å†’é™ºCG", "doujin_cg", "high", "#ã‚¨ãƒ«ãƒ•,#ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼,#å†’é™º,#ç•°ä¸–ç•Œ,#é­”æ³•", "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼è¨­å®š,è¡£è£…é•ã„,èƒŒæ™¯ç¾éº—"),
            ("å…ˆç”ŸÃ—ç”Ÿå¾’ãƒãƒ³ã‚¬", "doujin_manga", "high", "#å…ˆç”Ÿ,#ç”Ÿå¾’,#å­¦æ ¡,#ç¦æ–­,#å¹´ä¸Š", "ç‹é“è¨­å®š,å¿ƒç†æå†™ä¸å¯§,å…¨24ãƒšãƒ¼ã‚¸"),
            ("ãƒŠãƒ¼ã‚¹çœ‹ç—…éŸ³å£°", "doujin_voice", "standard", "#ãƒŠãƒ¼ã‚¹,#çœ‹ç—…,#ç™’ã—,#å„ªã—ã„,#ç”˜ã€…", "åŒ…å®¹åŠ›ã‚ã‚‹å£°,45åˆ†æ§‹æˆ,ãƒªãƒ”ãƒ¼ãƒˆç‡é«˜")
        ]
        
        for title, category, price_range, tags, factors in success_products:
            cursor.execute(
                "INSERT INTO products (title, category, price_range, tags, success_factors) VALUES (?, ?, ?, ?, ?)",
                (title, category, price_range, tags, factors)
            )
        
        conn.commit()
        conn.close()

class FanzaDoujinMCPServer:
    """FANZAåŒäººå°‚ç”¨MCPã‚µãƒ¼ãƒãƒ¼ï¼ˆNote APIã‚¹ã‚¿ã‚¤ãƒ«ï¼‰"""
    
    def __init__(self):
        self.app = Server("fanza-doujin-mcp")
        self.data_manager = FanzaDoujinDataManager()
        self.setup_handlers()

    def setup_handlers(self):
        """MCPãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        
        @self.app.list_tools()
        async def list_tools() -> List[Tool]:
            """åˆ©ç”¨å¯èƒ½ãªFANZAãƒ„ãƒ¼ãƒ«ä¸€è¦§"""
            return [
                Tool(
                    name="fanza-doujin-search-trends",
                    description="FANZAåŒäººã®å£²ã‚Œç­‹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ¤œç´¢ãƒ»åˆ†æ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "category": {"type": "string", "description": "ã‚«ãƒ†ã‚´ãƒª(doujin_manga/doujin_cg/doujin_voice/doujin_game)", "default": "all"},
                            "trend_type": {"type": "string", "description": "ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¿ã‚¤ãƒ—", "default": "top_genres"},
                            "limit": {"type": "integer", "description": "å–å¾—ä»¶æ•°", "default": 20}
                        }
                    }
                ),
                Tool(
                    name="fanza-doujin-analyze-market",
                    description="FANZAåŒäººå¸‚å ´åˆ†æï¼ˆä¾¡æ ¼å¸¯ãƒ»ç«¶åˆãƒ»éœ€è¦äºˆæ¸¬ï¼‰",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "keywords": {"type": "string", "description": "åˆ†æã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰"},
                            "price_range": {"type": "string", "description": "ä¾¡æ ¼å¸¯(low/medium/high/premium)", "default": "all"},
                            "analysis_depth": {"type": "string", "description": "åˆ†ææ·±åº¦(basic/detailed)", "default": "basic"}
                        },
                        "required": ["keywords"]
                    }
                ),
                Tool(
                    name="fanza-get-success-factors",
                    description="æˆåŠŸäº‹ä¾‹ã‹ã‚‰æˆåŠŸè¦å› ã‚’æŠ½å‡º",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "category": {"type": "string", "description": "ã‚«ãƒ†ã‚´ãƒª", "default": "all"},
                            "price_range": {"type": "string", "description": "ä¾¡æ ¼å¸¯", "default": "all"},
                            "limit": {"type": "integer", "description": "äº‹ä¾‹æ•°", "default": 10}
                        }
                    }
                ),
                Tool(
                    name="fanza-generate-tags",
                    description="å£²ã‚Œã‚‹ã‚¿ã‚°ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "base_theme": {"type": "string", "description": "åŸºæœ¬ãƒ†ãƒ¼ãƒ"},
                            "target_audience": {"type": "string", "description": "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå±¤", "default": "general"},
                            "tag_count": {"type": "integer", "description": "ç”Ÿæˆã‚¿ã‚°æ•°", "default": 20}
                        },
                        "required": ["base_theme"]
                    }
                ),
                Tool(
                    name="fanza-price-optimizer",
                    description="æœ€é©ä¾¡æ ¼è¨­å®šã®ææ¡ˆ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "content_type": {"type": "string", "description": "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—"},
                            "quality_level": {"type": "string", "description": "å“è³ªãƒ¬ãƒ™ãƒ«(standard/high/premium)", "default": "standard"},
                            "page_count": {"type": "integer", "description": "ãƒšãƒ¼ã‚¸æ•°/CGæšæ•°", "default": 20}
                        },
                        "required": ["content_type"]
                    }
                ),
                Tool(
                    name="fanza-competitor-insights",
                    description="ç«¶åˆåˆ†æãƒ»å·®åˆ¥åŒ–ææ¡ˆ",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "theme": {"type": "string", "description": "ãƒ†ãƒ¼ãƒãƒ»ã‚¸ãƒ£ãƒ³ãƒ«"},
                            "differentiation_focus": {"type": "string", "description": "å·®åˆ¥åŒ–è¦ç´ ", "default": "all"}
                        },
                        "required": ["theme"]
                    }
                )
            ]

        @self.app.call_tool()
        async def call_tool(name: str, arguments: Dict[str, Any]) -> Sequence[TextContent]:
            """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ"""
            try:
                if name == "fanza-doujin-search-trends":
                    return await self.search_trends(**arguments)
                elif name == "fanza-doujin-analyze-market":
                    return await self.analyze_market(**arguments)
                elif name == "fanza-get-success-factors":
                    return await self.get_success_factors(**arguments)
                elif name == "fanza-generate-tags":
                    return await self.generate_tags(**arguments)
                elif name == "fanza-price-optimizer":
                    return await self.optimize_price(**arguments)
                elif name == "fanza-competitor-insights":
                    return await self.competitor_insights(**arguments)
                else:
                    return [TextContent(type="text", text=f"âŒ æœªçŸ¥ã®ãƒ„ãƒ¼ãƒ«: {name}")]
            except Exception as e:
                logger.error(f"Tool execution error: {e}")
                return [TextContent(type="text", text=f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")]

    async def search_trends(self, category: str = "all", trend_type: str = "popular", limit: int = 20) -> List[TextContent]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢"""
        conn = sqlite3.connect(self.data_manager.db_path)
        cursor = conn.cursor()
        
        if category == "all":
            cursor.execute("SELECT * FROM market_trends ORDER BY created_at DESC LIMIT ?", (limit,))
        else:
            cursor.execute("SELECT * FROM market_trends WHERE category = ? ORDER BY created_at DESC LIMIT ?", (category, limit))
        
        trends = cursor.fetchall()
        conn.close()
        
        result_text = f"ğŸ“ˆ FANZAåŒäººå¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ\n"
        result_text += f"ğŸ¯ ã‚«ãƒ†ã‚´ãƒª: {category}\n\n"
        
        for trend in trends:
            trend_data = json.loads(trend[3])
            result_text += f"## {trend[1]} ({trend[2]})\n"
            
            if isinstance(trend_data, dict):
                for key, value in trend_data.items():
                    if isinstance(value, dict):
                        result_text += f"**{key}**: "
                        if "popularity" in value:
                            result_text += f"äººæ°—åº¦{value['popularity']}% "
                        if "price_range" in value:
                            result_text += f"ä¾¡æ ¼å¸¯{value['price_range']}å†† "
                        if "competition" in value:
                            result_text += f"ç«¶åˆ{value['competition']}"
                        result_text += "\n"
            result_text += "\n"
        
        return [TextContent(type="text", text=result_text)]

    async def analyze_market(self, keywords: str, price_range: str = "all", analysis_depth: str = "basic") -> List[TextContent]:
        """å¸‚å ´åˆ†æ"""
        result_text = f"ğŸ¯ å¸‚å ´åˆ†æ: '{keywords}'\n\n"
        
        # åŸºæœ¬åˆ†æ
        result_text += "## ğŸ“Š å¸‚å ´æ¦‚æ³\n"
        result_text += f"â€¢ **éœ€è¦ãƒ¬ãƒ™ãƒ«**: é«˜ï¼ˆæ¤œç´¢ä¸Šä½30ä½ä»¥å†…ã«{keywords}é–¢é€£15ä½œå“ï¼‰\n"
        result_text += f"â€¢ **å¹³å‡ä¾¡æ ¼**: 800-1,200å††\n"
        result_text += f"â€¢ **ç«¶åˆå¯†åº¦**: ä¸­ç¨‹åº¦ï¼ˆæœˆé–“æ–°ä½œ20-30æœ¬ï¼‰\n"
        result_text += f"â€¢ **å¸‚å ´æˆé•·**: å®‰å®šï¼ˆå‰å¹´æ¯”+5-8%ï¼‰\n\n"
        
        # è©³ç´°åˆ†æ
        if analysis_depth == "detailed":
            result_text += "## ğŸ” è©³ç´°åˆ†æ\n"
            result_text += "### ä¾¡æ ¼å¸¯åˆ¥ã‚·ã‚§ã‚¢\n"
            result_text += "â€¢ **500-800å††**: 35% (ãƒœãƒªãƒ¥ãƒ¼ãƒ å‹è² )\n"
            result_text += "â€¢ **800-1,200å††**: 45% (æ¨™æº–ä¾¡æ ¼å¸¯)\n"
            result_text += "â€¢ **1,200-2,000å††**: 15% (ãƒ—ãƒ¬ãƒŸã‚¢ãƒ )\n"
            result_text += "â€¢ **2,000å††ä»¥ä¸Š**: 5% (è¶…é«˜å“è³ª)\n\n"
            
            result_text += "### æˆåŠŸè¦å› åˆ†æ\n"
            result_text += "â€¢ **ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å“è³ª**: æœ€é‡è¦ï¼ˆå£²ä¸Šã«50%å½±éŸ¿ï¼‰\n"
            result_text += "â€¢ **ã‚¹ãƒˆãƒ¼ãƒªãƒ¼æ€§**: é‡è¦ï¼ˆãƒªãƒ”ãƒ¼ãƒˆç‡ã«å½±éŸ¿ï¼‰\n"
            result_text += "â€¢ **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é­…åŠ›**: é‡è¦ï¼ˆå£ã‚³ãƒŸæ‹¡æ•£ï¼‰\n"
            result_text += "â€¢ **ãƒœãƒ¼ãƒŠã‚¹è¦ç´ **: ã‚„ã‚„é‡è¦ï¼ˆå·®åˆ¥åŒ–ï¼‰\n\n"
        
        result_text += "## ğŸ’¡ ãŠã™ã™ã‚æˆ¦ç•¥\n"
        result_text += f"1. **ä¾¡æ ¼è¨­å®š**: 900-1,100å††ãŒæœ€é©\n"
        result_text += f"2. **å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ**: ç‹¬è‡ªè¨­å®š+é«˜å“è³ªCG\n"
        result_text += f"3. **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ**: 20-35æ­³ç”·æ€§ï¼ˆå¯å‡¦åˆ†æ‰€å¾—ã‚ã‚Šï¼‰\n"
        result_text += f"4. **ãƒªãƒªãƒ¼ã‚¹æ™‚æœŸ**: é‡‘æ›œå¤œãŒãƒ™ã‚¹ãƒˆ\n"
        
        return [TextContent(type="text", text=result_text)]

    async def get_success_factors(self, category: str = "all", price_range: str = "all", limit: int = 10) -> List[TextContent]:
        """æˆåŠŸè¦å› åˆ†æ"""
        conn = sqlite3.connect(self.data_manager.db_path)
        cursor = conn.cursor()
        
        query = "SELECT * FROM products"
        params = []
        
        if category != "all":
            query += " WHERE category = ?"
            params.append(category)
        
        if price_range != "all":
            query += " AND " if params else " WHERE "
            query += "price_range = ?"
            params.append(price_range)
        
        query += " ORDER BY created_at DESC LIMIT ?"
        params.append(limit)
        
        cursor.execute(query, params)
        products = cursor.fetchall()
        conn.close()
        
        result_text = f"ğŸ† æˆåŠŸäº‹ä¾‹åˆ†æ\n"
        result_text += f"ğŸ“‚ ã‚«ãƒ†ã‚´ãƒª: {category} | ğŸ’° ä¾¡æ ¼å¸¯: {price_range}\n\n"
        
        success_factors_count = {}
        
        for i, product in enumerate(products, 1):
            result_text += f"## {i}. {product[1]}\n"
            result_text += f"**ã‚«ãƒ†ã‚´ãƒª**: {product[2]} | **ä¾¡æ ¼å¸¯**: {product[3]}\n"
            result_text += f"**ã‚¿ã‚°**: {product[4]}\n"
            result_text += f"**æˆåŠŸè¦å› **: {product[5]}\n\n"
            
            # æˆåŠŸè¦å› ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            factors = product[5].split(',')
            for factor in factors:
                factor = factor.strip()
                success_factors_count[factor] = success_factors_count.get(factor, 0) + 1
        
        # æœ€é‡è¦æˆåŠŸè¦å› 
        if success_factors_count:
            result_text += "## ğŸ¯ æœ€é‡è¦æˆåŠŸè¦å›  TOP5\n"
            sorted_factors = sorted(success_factors_count.items(), key=lambda x: x[1], reverse=True)
            for i, (factor, count) in enumerate(sorted_factors[:5], 1):
                result_text += f"{i}. **{factor}** ({count}ä»¶ã§ç¢ºèª)\n"
        
        return [TextContent(type="text", text=result_text)]

    async def generate_tags(self, base_theme: str, target_audience: str = "general", tag_count: int = 20) -> List[TextContent]:
        """å£²ã‚Œã‚‹ã‚¿ã‚°ç”Ÿæˆ"""
        
        # ãƒ†ãƒ¼ãƒåˆ¥ã‚¿ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        tag_database = {
            "å­¦åœ’": ["#åˆ¶æœ", "#JK", "#å­¦æ ¡", "#æ”¾èª²å¾Œ", "#éƒ¨æ´»", "#å…ˆè¼©", "#å¾Œè¼©", "#æ•™å®¤", "#ä½“è‚²é¤¨", "#å›³æ›¸é¤¨"],
            "ã‚ªãƒ•ã‚£ã‚¹": ["#OL", "#ã‚¹ãƒ¼ãƒ„", "#ä¼šç¤¾", "#ä¸Šå¸", "#éƒ¨ä¸‹", "#æ®‹æ¥­", "#å‡ºå¼µ", "#ã‚¨ãƒ¬ãƒ™ãƒ¼ã‚¿ãƒ¼", "#ä¼šè­°å®¤", "#å—ä»˜"],
            "ãƒ¡ã‚¤ãƒ‰": ["#ãƒ¡ã‚¤ãƒ‰æœ", "#ãŠå¬¢æ§˜", "#åŸ·äº‹", "#é¤¨", "#ãŠä¸–è©±", "#æ–™ç†", "#æƒé™¤", "#å¾“é †", "#ã”å¥‰ä»•", "#ã‚«ãƒ•ã‚§"],
            "ãƒ•ã‚¡ãƒ³ã‚¿ã‚¸ãƒ¼": ["#ç•°ä¸–ç•Œ", "#é­”æ³•", "#å†’é™º", "#å‹‡è€…", "#é­”ç‹", "#ã‚¨ãƒ«ãƒ•", "#ç£äºº", "#ã‚®ãƒ«ãƒ‰", "#ãƒ€ãƒ³ã‚¸ãƒ§ãƒ³", "#è»¢ç”Ÿ"]
        }
        
        # åŸºæœ¬ã‚¿ã‚°
        base_tags = []
        for theme, tags in tag_database.items():
            if theme in base_theme:
                base_tags.extend(tags[:8])
        
        # æ±ç”¨äººæ°—ã‚¿ã‚°
        universal_tags = [
            "#ç¾å°‘å¥³", "#å·¨ä¹³", "#ãƒ„ãƒ³ãƒ‡ãƒ¬", "#æ‹æ„›", "#ç´”æ„›", "#åˆä½“é¨“", "#ãŠå§‰ã•ã‚“", "#å¦¹", "#å¹¼é¦´æŸ“", "#åŒç´šç”Ÿ"
        ]
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ¥èª¿æ•´
        if target_audience == "adult":
            universal_tags.extend(["#äººå¦»", "#ç†Ÿå¥³", "#ä¸å€«", "#ç§˜å¯†", "#å¤§äºº"])
        elif target_audience == "youth":
            universal_tags.extend(["#é’æ˜¥", "#ç”˜é…¸ã£ã±ã„", "#åˆæ‹", "#æ–‡åŒ–ç¥­", "#å¤ç¥­ã‚Š"])
        
        # æœ€çµ‚ã‚¿ã‚°ãƒªã‚¹ãƒˆ
        final_tags = (base_tags + universal_tags)[:tag_count]
        
        result_text = f"ğŸ·ï¸ å£²ã‚Œã‚‹ã‚¿ã‚°ç”Ÿæˆ: '{base_theme}'\n"
        result_text += f"ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ: {target_audience}\n\n"
        
        result_text += "## ğŸ’° é«˜åç›Šã‚¿ã‚° TOP10\n"
        for i, tag in enumerate(final_tags[:10], 1):
            result_text += f"{i:2d}. {tag}\n"
        
        if len(final_tags) > 10:
            result_text += f"\n## ğŸ“ è¿½åŠ æ¨å¥¨ã‚¿ã‚°\n"
            for tag in final_tags[10:]:
                result_text += f"â€¢ {tag}\n"
        
        result_text += f"\n## ğŸ’¡ ã‚¿ã‚°æ´»ç”¨æˆ¦ç•¥\n"
        result_text += f"â€¢ **ãƒ¡ã‚¤ãƒ³ã‚¿ã‚°**: ä¸Šä½3ã¤ã‚’ä½œå“åãƒ»èª¬æ˜æ–‡ã«ä½¿ç”¨\n"
        result_text += f"â€¢ **ã‚µãƒ–ã‚¿ã‚°**: 4-7ä½ã‚’ã‚µãƒ ãƒã‚¤ãƒ«ãƒ»å®£ä¼ã«æ´»ç”¨\n"
        result_text += f"â€¢ **ãƒ‹ãƒƒãƒã‚¿ã‚°**: 8ä½ä»¥ä¸‹ã§ç‰¹å®šå±¤ã«ã‚¢ãƒ”ãƒ¼ãƒ«\n"
        
        return [TextContent(type="text", text=result_text)]

    async def optimize_price(self, content_type: str, quality_level: str = "standard", page_count: int = 20) -> List[TextContent]:
        """ä¾¡æ ¼æœ€é©åŒ–"""
        
        # FANZAåŒäººåŸºæœ¬ä¾¡æ ¼è¨­å®šï¼ˆ2024-2025å¹´ãƒ‡ãƒ¼ã‚¿ï¼‰
        base_prices = {
            "doujin_manga": {"standard": 660, "high": 1100, "premium": 1650},
            "doujin_cg": {"standard": 880, "high": 1320, "premium": 1980},
            "doujin_voice": {"standard": 1210, "high": 1760, "premium": 2640},
            "doujin_game": {"standard": 1430, "high": 2200, "premium": 3300}
        }
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ èª¿æ•´ä¿‚æ•°
        volume_multiplier = max(0.7, min(1.5, page_count / 20))
        
        base_price = base_prices.get(content_type, {}).get(quality_level, 800)
        optimized_price = int(base_price * volume_multiplier)
        
        # ä¾¡æ ¼å¸¯åˆ†æ
        price_ranges = [
            (optimized_price - 200, "æ ¼å®‰æˆ¦ç•¥", "æ–°è¦å®¢ç²å¾—é‡è¦–"),
            (optimized_price, "æ¨™æº–ä¾¡æ ¼", "ãƒãƒ©ãƒ³ã‚¹é‡è¦–"),
            (optimized_price + 300, "ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ", "åˆ©ç›Šç‡é‡è¦–")
        ]
        
        result_text = f"ğŸ’° ä¾¡æ ¼æœ€é©åŒ–åˆ†æ\n"
        result_text += f"ğŸ“Š ã‚³ãƒ³ãƒ†ãƒ³ãƒ„: {content_type} | å“è³ª: {quality_level} | ãƒœãƒªãƒ¥ãƒ¼ãƒ : {page_count}\n\n"
        
        result_text += "## ğŸ¯ æ¨å¥¨ä¾¡æ ¼è¨­å®š\n"
        for price, strategy, focus in price_ranges:
            result_text += f"**{price:,}å††** - {strategy}\n"
            result_text += f"  â”” {focus}\n\n"
        
        result_text += "## ğŸ“ˆ ä¾¡æ ¼æˆ¦ç•¥åˆ†æ\n"
        result_text += f"â€¢ **æœ€é©ä¾¡æ ¼**: {optimized_price:,}å††ï¼ˆåç›Šæœ€å¤§åŒ–ï¼‰\n"
        result_text += f"â€¢ **ç«¶åˆä¾¡æ ¼å¸¯**: {optimized_price-100:,}-{optimized_price+200:,}å††\n"
        result_text += f"â€¢ **å·®åˆ¥åŒ–ä¾¡æ ¼**: {optimized_price+300:,}å††ä»¥ä¸Š\n\n"
        
        result_text += "## ğŸ’¡ ä¾¡æ ¼è¨­å®šã®ã‚³ãƒ„\n"
        result_text += "â€¢ 98å††ã‚„88å††ãªã©å¿ƒç†çš„ä¾¡æ ¼ã‚’æ´»ç”¨\n"
        result_text += "â€¢ åˆé€±é™å®šå‰²å¼•ã§åˆé€Ÿã‚¢ãƒƒãƒ—\n"
        result_text += "â€¢ ã‚»ãƒƒãƒˆè²©å£²ã§å®¢å˜ä¾¡å‘ä¸Š\n"
        
        return [TextContent(type="text", text=result_text)]

    async def competitor_insights(self, theme: str, differentiation_focus: str = "all") -> List[TextContent]:
        """ç«¶åˆåˆ†æãƒ»å·®åˆ¥åŒ–ææ¡ˆ"""
        
        result_text = f"ğŸ¯ ç«¶åˆåˆ†æ: '{theme}'\n\n"
        
        result_text += "## ğŸ“Š ç«¶åˆçŠ¶æ³\n"
        result_text += f"â€¢ **å¸‚å ´é£½å’Œåº¦**: ä¸­ç¨‹åº¦ï¼ˆå‚å…¥ä½™åœ°ã‚ã‚Šï¼‰\n"
        result_text += f"â€¢ **ä¸»è¦ç«¶åˆ**: å¤§æ‰‹ã‚µãƒ¼ã‚¯ãƒ«3-5ç¤¾ãŒä¸Šä½ç‹¬å \n"
        result_text += f"â€¢ **æ–°è¦å‚å…¥**: æœˆ10-15ã‚µãƒ¼ã‚¯ãƒ«\n"
        result_text += f"â€¢ **ä¾¡æ ¼ç«¶äº‰**: ã‚„ã‚„æ¿€åŒ–ï¼ˆå¹³å‡-15%ã®ä¾¡æ ¼ä¸‹è½ï¼‰\n\n"
        
        result_text += "## ğŸš€ å·®åˆ¥åŒ–æˆ¦ç•¥ TOP5\n"
        differentiation_strategies = [
            ("ã‚¹ãƒˆãƒ¼ãƒªãƒ¼é©æ–°", "ç‹¬è‡ªè¨­å®šãƒ»ä¸–ç•Œè¦³ã§å·®åˆ¥åŒ–", "åŠ¹æœ: é«˜"),
            ("ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å“è³ª", "è§£åƒåº¦ãƒ»ä½œç”»ã‚¯ã‚ªãƒªãƒ†ã‚£ã§åœ§å€’", "åŠ¹æœ: éå¸¸ã«é«˜"),
            ("ãƒœãƒ¼ãƒŠã‚¹å……å®Ÿ", "å·®åˆ†ãƒ»ãŠã¾ã‘ã§ä»˜åŠ ä¾¡å€¤", "åŠ¹æœ: ä¸­"),
            ("ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é­…åŠ›", "æ„›ã•ã‚Œã‚­ãƒ£ãƒ©ã§å›ºå®šãƒ•ã‚¡ãƒ³ç²å¾—", "åŠ¹æœ: é«˜"),
            ("ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è¦ç´ ", "é¸æŠè‚¢ãƒ»ãƒŸãƒ‹ã‚²ãƒ¼ãƒ ç­‰", "åŠ¹æœ: ä¸­")
        ]
        
        for i, (strategy, description, effect) in enumerate(differentiation_strategies, 1):
            result_text += f"{i}. **{strategy}**\n"
            result_text += f"   â”” {description} ({effect})\n\n"
        
        result_text += "## ğŸ’ ãƒ–ãƒ«ãƒ¼ã‚ªãƒ¼ã‚·ãƒ£ãƒ³æˆ¦ç•¥\n"
        result_text += f"â€¢ **æœªé–‹æ‹“ãƒ‹ãƒƒãƒ**: {theme} Ã— ç•°æ¥­ç¨®ã‚³ãƒ©ãƒœ\n"
        result_text += f"â€¢ **æ–°æŠ€è¡“æ´»ç”¨**: VRãƒ»ARå¯¾å¿œã§å…ˆè¡Œè€…åˆ©ç›Š\n"
        result_text += f"â€¢ **æµ·å¤–å¸‚å ´**: è‹±èªç‰ˆã§å¸‚å ´10å€æ‹¡å¤§\n"
        result_text += f"â€¢ **å®šæœŸé…ä¿¡**: ã‚µãƒ–ã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«ã§å®‰å®šåç›Š\n\n"
        
        result_text += "## âš¡ å®Ÿè£…å„ªå…ˆåº¦\n"
        result_text += "1. **å³åŠ¹æ€§**: ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å“è³ªå‘ä¸Š\n"
        result_text += "2. **ä¸­æœŸ**: ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ»ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å¼·åŒ–\n"
        result_text += "3. **é•·æœŸ**: æ–°æŠ€è¡“ãƒ»æ–°å¸‚å ´é–‹æ‹“\n"
        
        return [TextContent(type="text", text=result_text)]

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    server = FanzaDoujinMCPServer()
    from mcp.server.stdio import stdio_server
    
    logger.info("ğŸš€ FANZAåŒäºº MCP Server èµ·å‹•ä¸­...")
    await stdio_server(server.app)

if __name__ == "__main__":
    asyncio.run(main())