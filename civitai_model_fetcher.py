#!/usr/bin/env python3
"""
CivitAI Model Fetcher
====================
äººæ°—ãƒ¢ãƒ‡ãƒ«ãƒ»LoRAæƒ…å ±ã‚’è‡ªå‹•å–å¾—
"""

import json
import requests
from datetime import datetime
from pathlib import Path

class CivitAIFetcher:
    def __init__(self):
        self.base_url = "https://civitai.com/api/v1"
        self.cache_dir = Path("civitai_cache")
        self.cache_dir.mkdir(exist_ok=True)
        
    def fetch_trending_models(self, limit=10):
        """ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        print("ğŸ” CivitAIäººæ°—ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ä¸­...")
        
        # CivitAI API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        url = f"{self.base_url}/models"
        params = {
            "limit": limit,
            "sort": "Highest Rated",
            "period": "Week"
        }
        
        try:
            response = requests.get(url, params=params, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return self.parse_models(data.get("items", []))
            else:
                print(f"âš ï¸ APIå¿œç­”ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return self.get_fallback_models()
        except Exception as e:
            print(f"âš ï¸ æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
            return self.get_fallback_models()
    
    def parse_models(self, models):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ãƒ‘ãƒ¼ã‚¹"""
        parsed = []
        for model in models[:10]:
            parsed.append({
                "name": model.get("name", "Unknown"),
                "type": model.get("type", "Checkpoint"),
                "rating": model.get("stats", {}).get("rating", 0),
                "downloads": model.get("stats", {}).get("downloadCount", 0),
                "tags": model.get("tags", []),
                "description": model.get("description", "")[:200]
            })
        return parsed
    
    def get_fallback_models(self):
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®äººæ°—ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆ"""
        return [
            {
                "name": "Anything V5",
                "type": "Checkpoint", 
                "rating": 4.95,
                "downloads": 500000,
                "tags": ["anime", "stable", "general"],
                "description": "æœ€ã‚‚äººæ°—ã®ã‚¢ãƒ‹ãƒ¡ç³»ãƒ¢ãƒ‡ãƒ«"
            },
            {
                "name": "Realistic Vision V5",
                "type": "Checkpoint",
                "rating": 4.92,
                "downloads": 300000,
                "tags": ["photorealistic", "detailed"],
                "description": "é«˜å“è³ªãªãƒªã‚¢ãƒ«ç³»ãƒ¢ãƒ‡ãƒ«"
            },
            {
                "name": "DreamShaper V8",
                "type": "Checkpoint",
                "rating": 4.90,
                "downloads": 400000,
                "tags": ["versatile", "artistic"],
                "description": "ã‚¢ãƒ¼ãƒˆç³»ä¸‡èƒ½ãƒ¢ãƒ‡ãƒ«"
            }
        ]
    
    def fetch_popular_loras(self, limit=10):
        """äººæ°—LoRAã‚’å–å¾—"""
        print("ğŸ” äººæ°—LoRAã‚’å–å¾—ä¸­...")
        
        # ãƒ‡ãƒ¢ç”¨ã®äººæ°—LoRAãƒªã‚¹ãƒˆ
        popular_loras = [
            {
                "name": "Detail Tweaker LoRA",
                "weight_recommended": 0.7,
                "purpose": "ãƒ‡ã‚£ãƒ†ãƒ¼ãƒ«å‘ä¸Š",
                "compatibility": ["anime", "realistic"]
            },
            {
                "name": "Good hands - beta2",
                "weight_recommended": 0.8,
                "purpose": "æ‰‹ã®ä¿®æ­£",
                "compatibility": ["all"]
            },
            {
                "name": "Anime Tarot Card Art",
                "weight_recommended": 0.6,
                "purpose": "ã‚¿ãƒ­ãƒƒãƒˆã‚«ãƒ¼ãƒ‰é¢¨",
                "compatibility": ["anime", "artistic"]
            }
        ]
        
        return popular_loras
    
    def save_to_obsidian_format(self, models, loras):
        """Obsidianç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y-%m-%d")
        
        # Obsidianç”¨Markdownç”Ÿæˆ
        content = f"# CivitAI ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ {timestamp}\n\n"
        
        content += "## ğŸ”¥ äººæ°—Checkpoints\n\n"
        for i, model in enumerate(models[:5], 1):
            content += f"### {i}. {model['name']}\n"
            content += f"- **è©•ä¾¡**: â­{model['rating']}/5.0\n"
            content += f"- **DLæ•°**: {model['downloads']:,}\n"
            content += f"- **ã‚¿ã‚°**: {', '.join(model['tags'][:5])}\n"
            content += f"- **èª¬æ˜**: {model['description']}\n\n"
        
        content += "## ğŸ¨ äººæ°—LoRA\n\n"
        for lora in loras[:5]:
            content += f"### {lora['name']}\n"
            content += f"- **æ¨å¥¨Weight**: {lora['weight_recommended']}\n"
            content += f"- **ç”¨é€”**: {lora['purpose']}\n"
            content += f"- **äº’æ›æ€§**: {', '.join(lora['compatibility'])}\n\n"
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
        cache_file = self.cache_dir / f"civitai_trends_{timestamp}.md"
        with open(cache_file, "w", encoding="utf-8") as f:
            f.write(content)
        
        return cache_file
    
    def generate_recommendations(self, keyword):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«åŸºã¥ãæ¨å¥¨"""
        models = self.fetch_trending_models()
        loras = self.fetch_popular_loras()
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æ
        keyword_lower = keyword.lower()
        
        # æœ€é©ãªãƒ¢ãƒ‡ãƒ«é¸æŠ
        recommended_model = None
        for model in models:
            model_tags = [tag.lower() for tag in model.get("tags", [])]
            if any(tag in keyword_lower for tag in ["ã‚¢ãƒ‹ãƒ¡", "anime", "èŒãˆ"]):
                if "anime" in model_tags:
                    recommended_model = model
                    break
            elif any(tag in keyword_lower for tag in ["ãƒªã‚¢ãƒ«", "realistic", "å†™çœŸ"]):
                if "photorealistic" in model_tags or "realistic" in model_tags:
                    recommended_model = model
                    break
        
        if not recommended_model and models:
            recommended_model = models[0]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        
        # æ¨å¥¨LoRAé¸æŠ
        recommended_loras = []
        for lora in loras:
            if "all" in lora["compatibility"] or \
               any(compat in recommended_model.get("tags", []) for compat in lora["compatibility"]):
                recommended_loras.append(lora)
        
        return {
            "model": recommended_model,
            "loras": recommended_loras[:3],
            "obsidian_file": self.save_to_obsidian_format(models, loras)
        }

def main():
    import sys
    fetcher = CivitAIFetcher()
    
    print("ğŸ¤– CivitAI Model Intelligence")
    print("=" * 50)
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    keyword = " ".join(sys.argv[1:]) if len(sys.argv) > 1 else "anime girl poster"
    print(f"ç”Ÿæˆäºˆå®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}")
    
    print("\nğŸ“Š åˆ†æä¸­...")
    recommendations = fetcher.generate_recommendations(keyword)
    
    print("\nâœ… æ¨å¥¨è¨­å®š")
    print("-" * 50)
    
    if recommendations["model"]:
        model = recommendations["model"]
        print(f"\nğŸ¨ æ¨å¥¨Checkpoint: {model['name']}")
        print(f"   è©•ä¾¡: â­{model['rating']}/5.0")
        print(f"   DLæ•°: {model['downloads']:,}")
    
    print("\nğŸ”§ æ¨å¥¨LoRA:")
    for lora in recommendations["loras"]:
        print(f"   - {lora['name']} (weight: {lora['weight_recommended']})")
    
    print(f"\nğŸ“ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {recommendations['obsidian_file']}")
    print("\nğŸ’¡ ä½¿ç”¨æ³•: python3 civitai_model_fetcher.py [ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰]")

if __name__ == "__main__":
    main()