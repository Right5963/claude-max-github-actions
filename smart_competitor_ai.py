#!/usr/bin/env python3
"""
ã‚¹ãƒãƒ¼ãƒˆç«¶åˆåˆ†æAI
================
73è¡Œã§ãƒ©ã‚¤ãƒãƒ«ã‚’è‡ªå‹•åˆ†æã—ã¦å£²ä¸Šæ”¹å–„ææ¡ˆ
"""

import json
from datetime import datetime

def sample_competitor_data():
    """ã‚µãƒ³ãƒ—ãƒ«ç«¶åˆãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯ Obsidian ã‹ã‚‰è‡ªå‹•å–å¾—ï¼‰"""
    
    return {
        "hajimeæ°": {
            "å£²ä¸Šå•†å“": [
                "ç¾å°‘å¥³ã‚¢ãƒ‹ãƒ¡ãƒã‚¹ã‚¿ãƒ¼ A4ã‚µã‚¤ã‚º - 2800å††",
                "ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚¤ãƒ©ã‚¹ãƒˆ ãƒã‚¹ã‚¿ãƒ¼ - 1500å††", 
                "ã‚²ãƒ¼ãƒ ã‚­ãƒ£ãƒ© ãƒã‚¹ã‚¿ãƒ¼ A3 - 3500å††"
            ],
            "ç‰¹å¾´": ["ç¾å°‘å¥³ç³»ãŒå¤šã„", "ä¾¡æ ¼å¸¯1500-3500å††", "A4/A3ã‚µã‚¤ã‚ºä¸­å¿ƒ"]
        },
        "ã²ã‚…ã‚Œã˜æ°": {
            "å£²ä¸Šå•†å“": [
                "é™å®šãƒã‚¹ã‚¿ãƒ¼ é«˜ç”»è³ªå°åˆ· - 4200å††",
                "åŒäººèªŒé¢¨ã‚¤ãƒ©ã‚¹ãƒˆé›† - 2000å††",
                "å­£ç¯€é™å®šãƒ‡ã‚¶ã‚¤ãƒ³ - 2500å††"
            ],
            "ç‰¹å¾´": ["é™å®šæ„Ÿã‚’å¼·èª¿", "é«˜å“è³ªå°åˆ·ã‚¢ãƒ”ãƒ¼ãƒ«", "å­£ç¯€æ€§ã‚’æ´»ç”¨"]
        }
    }

def ai_analyze_competitors(data):
    """AIç«¶åˆåˆ†æ"""
    
    all_prices = []
    keywords = {}
    success_patterns = []
    
    for seller, info in data.items():
        for product in info["å£²ä¸Šå•†å“"]:
            # ä¾¡æ ¼æŠ½å‡º
            price = int(product.split(" - ")[1].replace("å††", ""))
            all_prices.append(price)
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
            words = ["ç¾å°‘å¥³", "ã‚ªãƒªã‚¸ãƒŠãƒ«", "ã‚²ãƒ¼ãƒ ", "é™å®š", "é«˜ç”»è³ª", "A4", "A3"]
            for word in words:
                if word in product:
                    keywords[word] = keywords.get(word, 0) + 1
    
    # AIåˆ†æçµæœ
    avg_price = sum(all_prices) / len(all_prices)
    top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:3]
    
    return {
        "ä¾¡æ ¼æˆ¦ç•¥": f"å¹³å‡ä¾¡æ ¼ {avg_price:.0f}å††ã€å£²ã‚Œç­‹ã¯2000-3500å††",
        "å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": [k for k, v in top_keywords],
        "ä»Šã™ãæ”¹å–„": [
            f"ä¾¡æ ¼ã‚’{avg_price:.0f}å††å‰å¾Œã«èª¿æ•´",
            f"ã‚¿ã‚¤ãƒˆãƒ«ã«ã€Œ{top_keywords[0][0]}ã€ã‚’å«ã‚ã‚‹", 
            "A4ã¾ãŸã¯A3ã‚µã‚¤ã‚ºã§çµ±ä¸€",
            "é™å®šæ„Ÿãƒ»é«˜å“è³ªã‚’ã‚¢ãƒ”ãƒ¼ãƒ«"
        ]
    }

def generate_today_action(analysis):
    """ä»Šæ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
    
    return [
        f"â–¡ ä¾¡æ ¼èª¿æ•´: {analysis['ä¾¡æ ¼æˆ¦ç•¥']}",
        f"â–¡ ã‚¿ã‚¤ãƒˆãƒ«ä¿®æ­£: {analysis['å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰']}ã‚’å«ã‚ã‚‹",
        f"â–¡ ãƒ©ã‚¤ãƒãƒ«æ–°ç€ãƒã‚§ãƒƒã‚¯ï¼ˆ5åˆ†ï¼‰",
        f"â–¡ {analysis['ä»Šã™ãæ”¹å–„'][0]}ã‚’å®Ÿè¡Œ"
    ]

def main():
    """73è¡Œã®ã‚¹ãƒãƒ¼ãƒˆåˆ†æ"""
    
    print("ğŸ¤– ã‚¹ãƒãƒ¼ãƒˆç«¶åˆåˆ†æAIï¼ˆ73è¡Œç‰ˆï¼‰")
    print("=" * 40)
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†æ
    data = sample_competitor_data()
    analysis = ai_analyze_competitors(data)
    today_actions = generate_today_action(analysis)
    
    # çµæœè¡¨ç¤º
    print(f"ğŸ’° {analysis['ä¾¡æ ¼æˆ¦ç•¥']}")
    print(f"ğŸ”‘ å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(analysis['å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰'])}")
    
    print(f"\nâœ… ä»Šã™ãæ”¹å–„:")
    for i, action in enumerate(analysis['ä»Šã™ãæ”¹å–„'], 1):
        print(f"{i}. {action}")
    
    print(f"\nğŸ“… ä»Šæ—¥ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
    for action in today_actions:
        print(f"{action}")
    
    # ç¶™ç¶šã‚·ã‚¹ãƒ†ãƒ 
    print(f"\nğŸ”„ ç¶™ç¶šæ–¹æ³•:")
    print("1. æ¯æ—¥5åˆ†: ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ")
    print("2. é€±1å›: ãƒ‡ãƒ¼ã‚¿æ›´æ–°")
    print("3. æœˆ1å›: æˆ¦ç•¥è¦‹ç›´ã—")
    
    # çµæœä¿å­˜
    result = {
        "analysis": analysis,
        "actions": today_actions,
        "timestamp": datetime.now().isoformat()
    }
    
    with open('smart_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†æçµæœä¿å­˜: smart_analysis.json")

if __name__ == "__main__":
    main()