#!/usr/bin/env python3
"""
Git-Knowledge Connector (ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—)
=====================================
Gitã‚³ãƒŸãƒƒãƒˆã‹ã‚‰ObsidiançŸ¥è­˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¸ã®è‡ªå‹•çµ±åˆ

é©å‘½çš„æ©Ÿèƒ½:
- ã‚³ãƒŸãƒƒãƒˆå†…å®¹ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
- è‡ªå‹•çš„ãªå­¦ç¿’è¦ç´ ç‰¹å®š
- ObsidiançŸ¥è­˜ãƒãƒ¼ãƒˆç”Ÿæˆ
- é–‹ç™ºå±¥æ­´ã®çŸ¥è­˜åŒ–
"""

import os
import json
import subprocess
import re
from datetime import datetime
from pathlib import Path
import hashlib

class GitKnowledgeConnector:
    def __init__(self, repo_path="/mnt/c/Claude Code/tool"):
        self.repo_path = repo_path
        self.obsidian_bridge_script = "./mcp_bridge_extended.sh"
        self.knowledge_db = ".git_knowledge_db.json"
        self.patterns_db = ".development_patterns.json"
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜ã®åŸºæº–
        self.code_patterns = {
            "refactoring": [r"refactor", r"cleanup", r"reorganize", r"optimize"],
            "feature_addition": [r"add", r"implement", r"create", r"new"],
            "bug_fix": [r"fix", r"bug", r"error", r"issue", r"patch"],
            "documentation": [r"doc", r"readme", r"comment", r"explain"],
            "testing": [r"test", r"spec", r"verify", r"validate"],
            "integration": [r"integrate", r"connect", r"bridge", r"link"],
            "automation": [r"auto", r"script", r"batch", r"daemon"],
            "security": [r"security", r"auth", r"permission", r"encrypt"],
            "performance": [r"performance", r"speed", r"optimize", r"efficient"]
        }
        
        # å­¦ç¿’è¦ç´ ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        self.learning_indicators = [
            "learned", "discovered", "found", "realized", "understood",
            "mistake", "error", "problem", "solution", "approach",
            "better", "improved", "enhanced", "optimized"
        ]
    
    def load_knowledge_db(self):
        """çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.knowledge_db, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {
                "patterns": {},
                "learnings": {},
                "connections": {},
                "stats": {"total_commits": 0, "patterns_identified": 0}
            }
    
    def save_knowledge_db(self, data):
        """çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿å­˜"""
        with open(self.knowledge_db, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def get_commit_info(self, commit_hash="HEAD"):
        """Gitã‚³ãƒŸãƒƒãƒˆæƒ…å ±ã®å–å¾—"""
        try:
            # ã‚³ãƒŸãƒƒãƒˆæƒ…å ±
            commit_info = subprocess.run([
                "git", "log", "-1", "--format=%H|%s|%B|%an|%ad", commit_hash
            ], cwd=self.repo_path, capture_output=True, text=True).stdout.strip()
            
            if not commit_info:
                return None
                
            parts = commit_info.split('|')
            hash_val, subject, body, author, date = parts[0], parts[1], parts[2], parts[3], parts[4]
            
            # å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
            files_changed = subprocess.run([
                "git", "diff-tree", "--no-commit-id", "--name-only", "-r", commit_hash
            ], cwd=self.repo_path, capture_output=True, text=True).stdout.strip().split('\n')
            
            # çµ±è¨ˆæƒ…å ±
            stats = subprocess.run([
                "git", "diff", "--shortstat", f"{commit_hash}^", commit_hash
            ], cwd=self.repo_path, capture_output=True, text=True).stdout.strip()
            
            return {
                "hash": hash_val,
                "subject": subject,
                "body": body,
                "author": author,
                "date": date,
                "files_changed": [f for f in files_changed if f],
                "stats": stats
            }
        except Exception as e:
            print(f"âŒ Gitã‚³ãƒŸãƒƒãƒˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def analyze_commit_patterns(self, commit_info):
        """ã‚³ãƒŸãƒƒãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ†æ"""
        if not commit_info:
            return []
        
        full_text = f"{commit_info['subject']} {commit_info['body']}".lower()
        identified_patterns = []
        
        for pattern_name, keywords in self.code_patterns.items():
            for keyword in keywords:
                if re.search(keyword, full_text):
                    identified_patterns.append(pattern_name)
                    break
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã«ã‚ˆã‚‹è¿½åŠ åˆ†æ
        file_types = set()
        for file_path in commit_info['files_changed']:
            ext = Path(file_path).suffix
            if ext:
                file_types.add(ext)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«åŸºã¥ããƒ‘ã‚¿ãƒ¼ãƒ³æ¨å®š
        if '.py' in file_types:
            identified_patterns.append('python_development')
        if '.sh' in file_types:
            identified_patterns.append('script_development')
        if '.md' in file_types:
            identified_patterns.append('documentation')
        if '.json' in file_types:
            identified_patterns.append('configuration')
        
        return list(set(identified_patterns))  # é‡è¤‡é™¤å»
    
    def extract_learning_elements(self, commit_info):
        """å­¦ç¿’è¦ç´ ã®æŠ½å‡º"""
        if not commit_info:
            return []
        
        full_text = f"{commit_info['subject']} {commit_info['body']}"
        learnings = []
        
        # å­¦ç¿’æŒ‡æ¨™ã®æ¤œå‡º
        for indicator in self.learning_indicators:
            if indicator in full_text.lower():
                # å‘¨è¾ºãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦å­¦ç¿’è¦ç´ ã¨ã—ã¦è¨˜éŒ²
                sentences = re.split(r'[.!?]', full_text)
                for sentence in sentences:
                    if indicator in sentence.lower():
                        learnings.append(sentence.strip())
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã‚„å¤‰æ›´è¦æ¨¡ã‹ã‚‰ã®æ¨å®š
        file_count = len(commit_info['files_changed'])
        if file_count > 10:
            learnings.append(f"å¤§è¦æ¨¡å¤‰æ›´ ({file_count}ãƒ•ã‚¡ã‚¤ãƒ«) - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç†è§£ãŒé€²ã‚“ã ")
        
        if 'fix' in commit_info['subject'].lower():
            learnings.append("å•é¡Œè§£æ±ºã‚¹ã‚­ãƒ«ã®å‘ä¸Š - ãƒã‚°ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¿’å¾—")
        
        if 'refactor' in commit_info['subject'].lower():
            learnings.append("ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æŠ€è¡“ã®å¿œç”¨")
        
        return learnings
    
    def generate_obsidian_note(self, commit_info, patterns, learnings):
        """ObsidiançŸ¥è­˜ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        timestamp = datetime.now().strftime("%Y-%m-%d_%H%M%S")
        commit_short = commit_info['hash'][:8]
        
        # ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç‰¹å®š
        main_pattern = patterns[0] if patterns else "general_development"
        
        note_content = f"""# é–‹ç™ºæ´å¯Ÿ: {commit_info['subject']}

## ğŸ“Š åŸºæœ¬æƒ…å ±
- **ã‚³ãƒŸãƒƒãƒˆ**: `{commit_short}`
- **æ—¥æ™‚**: {commit_info['date']}
- **ä½œæˆè€…**: {commit_info['author']}
- **å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(commit_info['files_changed'])}

## ğŸ” è­˜åˆ¥ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
{self._format_patterns(patterns)}

## ğŸ“š å­¦ç¿’è¦ç´ 
{self._format_learnings(learnings)}

## ğŸ“ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«
{self._format_files(commit_info['files_changed'])}

## ğŸ“ˆ çµ±è¨ˆ
```
{commit_info['stats']}
```

## ğŸ”— é–¢é€£çŸ¥è­˜
{self._generate_knowledge_links(patterns)}

## ğŸ’¡ ä»Šå¾Œã¸ã®ç¤ºå”†
{self._generate_future_insights(patterns, learnings)}

---
*è‡ªå‹•ç”Ÿæˆ: Git-Knowledge Connector*
*ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}*
"""
        
        return {
            "filename": f"Development_Insights_{timestamp}_{main_pattern}.md",
            "content": note_content,
            "patterns": patterns,
            "learnings": learnings
        }
    
    def _format_patterns(self, patterns):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not patterns:
            return "- ä¸€èˆ¬çš„ãªé–‹ç™ºä½œæ¥­"
        
        formatted = []
        for pattern in patterns:
            emoji = self._get_pattern_emoji(pattern)
            formatted.append(f"- {emoji} **{pattern.replace('_', ' ').title()}**")
        
        return '\n'.join(formatted)
    
    def _format_learnings(self, learnings):
        """å­¦ç¿’è¦ç´ ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not learnings:
            return "- ç¶™ç¶šçš„ãªé–‹ç™ºçµŒé¨“ã®è“„ç©"
        
        formatted = []
        for learning in learnings:
            formatted.append(f"- ğŸ’¡ {learning}")
        
        return '\n'.join(formatted)
    
    def _format_files(self, files):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not files:
            return "- ãªã—"
        
        formatted = []
        for file_path in files[:10]:  # æœ€å¤§10å€‹ã¾ã§è¡¨ç¤º
            ext = Path(file_path).suffix
            emoji = self._get_file_emoji(ext)
            formatted.append(f"- {emoji} `{file_path}`")
        
        if len(files) > 10:
            formatted.append(f"- ... ä»– {len(files) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")
        
        return '\n'.join(formatted)
    
    def _generate_knowledge_links(self, patterns):
        """çŸ¥è­˜ãƒªãƒ³ã‚¯ã®ç”Ÿæˆ"""
        links = []
        
        for pattern in patterns:
            if pattern == "refactoring":
                links.append("- [[ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æ‰‹æ³•]]")
                links.append("- [[ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š]]")
            elif pattern == "feature_addition":
                links.append("- [[æ©Ÿèƒ½é–‹ç™ºãƒ—ãƒ­ã‚»ã‚¹]]")
                links.append("- [[è¦ä»¶åˆ†æ]]")
            elif pattern == "bug_fix":
                links.append("- [[ãƒ‡ãƒãƒƒã‚°æŠ€è¡“]]")
                links.append("- [[ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°]]")
            elif pattern == "automation":
                links.append("- [[è‡ªå‹•åŒ–æˆ¦ç•¥]]")
                links.append("- [[ã‚¹ã‚¯ãƒªãƒ—ãƒˆé–‹ç™º]]")
        
        if not links:
            links.append("- [[é–‹ç™ºãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹]]")
        
        return '\n'.join(links)
    
    def _generate_future_insights(self, patterns, learnings):
        """å°†æ¥ã¸ã®ç¤ºå”†ã®ç”Ÿæˆ"""
        insights = []
        
        if "refactoring" in patterns:
            insights.append("- ã‚ˆã‚Šè‰¯ã„ã‚³ãƒ¼ãƒ‰æ§‹é€ ã®æ¢æ±‚ã‚’ç¶™ç¶š")
        if "automation" in patterns:
            insights.append("- è‡ªå‹•åŒ–ã®ç¯„å›²ã‚’ã•ã‚‰ã«æ‹¡å¤§æ¤œè¨")
        if "integration" in patterns:
            insights.append("- ã‚·ã‚¹ãƒ†ãƒ é–“é€£æºã®æ›´ãªã‚‹æœ€é©åŒ–")
        
        if len(learnings) > 2:
            insights.append("- å­¦ç¿’å¯†åº¦ãŒé«˜ã„ - çŸ¥è­˜ã®ä½“ç³»åŒ–ã‚’æ¤œè¨")
        
        if not insights:
            insights.append("- ç¶™ç¶šçš„æ”¹å–„ã®æ©Ÿä¼šã‚’æ¢ã‚‹")
        
        return '\n'.join(insights)
    
    def _get_pattern_emoji(self, pattern):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµµæ–‡å­—"""
        emoji_map = {
            "refactoring": "ğŸ”§",
            "feature_addition": "âœ¨",
            "bug_fix": "ğŸ›",
            "documentation": "ğŸ“š",
            "testing": "ğŸ§ª",
            "integration": "ğŸ”—",
            "automation": "ğŸ¤–",
            "security": "ğŸ”’",
            "performance": "âš¡",
            "python_development": "ğŸ",
            "script_development": "ğŸ“œ"
        }
        return emoji_map.get(pattern, "ğŸ’»")
    
    def _get_file_emoji(self, ext):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­åˆ¥çµµæ–‡å­—"""
        emoji_map = {
            ".py": "ğŸ",
            ".sh": "ğŸ“œ",
            ".md": "ğŸ“",
            ".json": "ğŸ“‹",
            ".txt": "ğŸ“„",
            ".yaml": "âš™ï¸",
            ".yml": "âš™ï¸"
        }
        return emoji_map.get(ext, "ğŸ“")
    
    def save_to_obsidian(self, note_data):
        """Obsidianã¸ã®ä¿å­˜"""
        try:
            # ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜ï¼ˆç¢ºå®Ÿãªå‹•ä½œç¢ºèªï¼‰
            local_dir = "knowledge_notes"
            os.makedirs(local_dir, exist_ok=True)
            local_path = os.path.join(local_dir, note_data['filename'])
            
            with open(local_path, 'w', encoding='utf-8') as f:
                f.write(note_data['content'])
            
            print(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«çŸ¥è­˜ãƒãƒ¼ãƒˆä¿å­˜: {local_path}")
            
            # Obsidianä¿å­˜ã‚‚è©¦è¡Œï¼ˆã‚¨ãƒ©ãƒ¼ãŒã‚ã£ã¦ã‚‚ç¶™ç¶šï¼‰
            try:
                obsidian_path = f"Development_Insights/{note_data['filename']}"
                
                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                result = subprocess.run([
                    "powershell.exe", "-Command",
                    f"$content = @'\n{note_data['content']}\n'@; $content | Out-File -FilePath 'G:\\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\\Obsidian Vault\\{obsidian_path}' -Encoding UTF8 -Force"
                ], capture_output=True, text=True, timeout=10)
                
                if result.returncode == 0:
                    print(f"âœ… Obsidianãƒãƒ¼ãƒˆä¿å­˜æˆåŠŸ: {obsidian_path}")
                else:
                    print(f"âš ï¸ Obsidianä¿å­˜ã‚¹ã‚­ãƒƒãƒ—: ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™")
                    
            except Exception as obs_error:
                print(f"âš ï¸ Obsidianä¿å­˜ã‚¹ã‚­ãƒƒãƒ—: {str(obs_error)[:50]}...")
            
            return True
                
        except Exception as e:
            print(f"âŒ çŸ¥è­˜ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def update_knowledge_database(self, commit_info, patterns, learnings):
        """çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ›´æ–°"""
        db = self.load_knowledge_db()
        
        # çµ±è¨ˆæ›´æ–°
        db["stats"]["total_commits"] += 1
        db["stats"]["patterns_identified"] += len(patterns)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦ã®æ›´æ–°
        for pattern in patterns:
            if pattern not in db["patterns"]:
                db["patterns"][pattern] = {"count": 0, "examples": []}
            db["patterns"][pattern]["count"] += 1
            db["patterns"][pattern]["examples"].append({
                "commit": commit_info['hash'][:8],
                "subject": commit_info['subject'],
                "date": commit_info['date']
            })
        
        # å­¦ç¿’è¦ç´ ã®è“„ç©
        commit_key = commit_info['hash'][:8]
        db["learnings"][commit_key] = {
            "elements": learnings,
            "patterns": patterns,
            "date": commit_info['date']
        }
        
        self.save_knowledge_db(db)
        return db
    
    def process_commit(self, commit_hash="HEAD"):
        """ã‚³ãƒŸãƒƒãƒˆã®å®Œå…¨å‡¦ç†"""
        print(f"ğŸ” Git-Knowledge Connector é–‹å§‹")
        print(f"å‡¦ç†å¯¾è±¡: {commit_hash}")
        print("=" * 50)
        
        # 1. ã‚³ãƒŸãƒƒãƒˆæƒ…å ±å–å¾—
        commit_info = self.get_commit_info(commit_hash)
        if not commit_info:
            print("âŒ ã‚³ãƒŸãƒƒãƒˆæƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        print(f"ğŸ“ ã‚³ãƒŸãƒƒãƒˆ: {commit_info['subject']}")
        print(f"ğŸ“ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«: {len(commit_info['files_changed'])}å€‹")
        
        # 2. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        patterns = self.analyze_commit_patterns(commit_info)
        print(f"ğŸ” è­˜åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³: {', '.join(patterns) if patterns else 'ãªã—'}")
        
        # 3. å­¦ç¿’è¦ç´ æŠ½å‡º
        learnings = self.extract_learning_elements(commit_info)
        print(f"ğŸ’¡ å­¦ç¿’è¦ç´ : {len(learnings)}å€‹")
        
        # 4. Obsidianãƒãƒ¼ãƒˆç”Ÿæˆ
        note_data = self.generate_obsidian_note(commit_info, patterns, learnings)
        print(f"ğŸ“” ãƒãƒ¼ãƒˆç”Ÿæˆ: {note_data['filename']}")
        
        # 5. Obsidianã«ä¿å­˜ï¼ˆåŸºæœ¬ç‰ˆï¼‰
        if self.save_to_obsidian(note_data):
            print("âœ… åŸºæœ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†")
            
            # 6. AIæœ€é©åŒ–çµ±åˆå®Ÿè¡Œ
            try:
                from obsidian_knowledge_integrator import ObsidianKnowledgeIntegrator
                print("ğŸ§  AIæœ€é©åŒ–çµ±åˆé–‹å§‹...")
                
                integrator = ObsidianKnowledgeIntegrator()
                latest_file = os.path.join("knowledge_notes", note_data['filename'])
                
                integration_result = integrator.integrate_knowledge_note(latest_file)
                
                if integration_result.get("success"):
                    print("ğŸ‰ å®Œå…¨AIçµ±åˆå®Œäº†ï¼")
                    print(f"ğŸ“ çµ±åˆå…ˆ: {integration_result.get('path', 'ãƒ­ãƒ¼ã‚«ãƒ«')}")
                    print(f"ğŸ·ï¸ ã‚¿ã‚°æ•°: {len(integration_result.get('metadata', {}).get('tags', []))}å€‹")
                    print(f"ğŸ”— é–¢é€£ãƒãƒ¼ãƒˆ: {len(integration_result.get('related_notes', []))}å€‹")
                else:
                    print("âš ï¸ çµ±åˆã¯éƒ¨åˆ†çš„å®Œäº†")
                    
            except Exception as integration_error:
                print(f"âš ï¸ AIçµ±åˆã‚¹ã‚­ãƒƒãƒ—: {str(integration_error)[:50]}...")
        
        # 7. çŸ¥è­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
        db = self.update_knowledge_database(commit_info, patterns, learnings)
        print(f"ğŸ“Š ç´¯è¨ˆã‚³ãƒŸãƒƒãƒˆ: {db['stats']['total_commits']}å›")
        print(f"ğŸ¯ ç´¯è¨ˆãƒ‘ã‚¿ãƒ¼ãƒ³: {db['stats']['patterns_identified']}å€‹")
        
        print("=" * 50)
        print("ğŸ‰ å®Œå…¨Git-Knowledgeçµ±åˆå®Œäº†ï¼")
        
        return True
    
    def show_knowledge_stats(self):
        """çŸ¥è­˜çµ±è¨ˆã®è¡¨ç¤º"""
        db = self.load_knowledge_db()
        
        print("ğŸ“Š Git-Knowledgeçµ±åˆçµ±è¨ˆ")
        print("=" * 30)
        print(f"ç·ã‚³ãƒŸãƒƒãƒˆæ•°: {db['stats']['total_commits']}")
        print(f"è­˜åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: {db['stats']['patterns_identified']}")
        
        if db["patterns"]:
            print("\nğŸ” ãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦:")
            sorted_patterns = sorted(db["patterns"].items(), 
                                   key=lambda x: x[1]["count"], 
                                   reverse=True)
            
            for pattern, data in sorted_patterns[:10]:
                emoji = self._get_pattern_emoji(pattern)
                print(f"  {emoji} {pattern.replace('_', ' ').title()}: {data['count']}å›")
        
        return db

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import sys
    
    connector = GitKnowledgeConnector()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "stats":
            connector.show_knowledge_stats()
        elif sys.argv[1] == "process":
            commit_hash = sys.argv[2] if len(sys.argv) > 2 else "HEAD"
            connector.process_commit(commit_hash)
        else:
            print("ä½¿ç”¨æ–¹æ³•:")
            print("  python3 git_knowledge_connector.py process [commit_hash]")
            print("  python3 git_knowledge_connector.py stats")
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€æ–°ã‚³ãƒŸãƒƒãƒˆã‚’å‡¦ç†
        connector.process_commit()

if __name__ == "__main__":
    main()